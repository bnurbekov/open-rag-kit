# ğŸ“š Open RAG Template

Open RAG Template is a plug-and-play Retrieval-Augmented Generation (RAG) framework built with LangChain. It lets you instantly chat with your own documents (PDF, Markdown, CSV, text, etc.) â€” while showcasing best practices in prompt engineering, retrieval design, agents, evaluation, and fine-tuning.

## âš¡ï¸ Why this project?

Most RAG tutorials are toy-level. This repo gives you a production-ready, modular, open-source template you can actually use, extend, and learn from.

## âœ¨ Features

ğŸ“‚ Multi-format ingestion â†’ PDF, Markdown, TXT, CSV loaders out of the box.

ğŸ” Advanced retrieval â†’ FAISS vector store (default) + hybrid search + metadata filtering.

ğŸ§© Prompt engineering â†’ Well-structured system/user prompts with context injection.

ğŸ¤– Agent mode (LangChain) â†’ SQL queries, calculator, and web search tools included.

ğŸ“Š Evaluation harness â†’ Test factuality, relevance, and grounding with LLM-based metrics.

ğŸ›ï¸ Configurable â†’ Easily adjust chunk sizes, embedding models, and retrieval settings.

ğŸš€ Deploy anywhere â†’ Run locally (Docker, pip) or in the cloud (AWS/GCP).

## ğŸ–¼ï¸ Demo

<p align="center"> <img src="docs/demo.gif" width="600" alt="Demo: Chat with your docs" /> </p>

### Quick Start

Chat with your own PDF in 3 steps:

git clone https://github.com/your-username/open-rag-template.git
cd open-rag-template
pip install -r requirements.txt
export OPENAI_API_KEY="your-api-key-here"
streamlit run src/app.py


Then open http://localhost:8501
 ğŸ‰

## ğŸ—ï¸ Architecture

<p align="center"> <img src="docs/architecture.png" width="650" alt="Architecture diagram" /> </p>

1. Ingest documents â†’ chunk + embed into FAISS (or another DB).
2. Retrieve relevant chunks per query.
3. Construct prompt with query + context.
4. Generate answer with an LLM (OpenAI, Anthropic, Llama 3, etc.).
5. (Optional) Agent â†’ use tools like SQL or web search if needed.
6. Evaluate outputs with metrics + logs.

## ğŸ“‚ Project Structure
open-rag-template/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingest/         # PDF/Markdown/CSV loaders
â”‚   â”œâ”€â”€ embeddings/     # Vectorstore + retriever setup
â”‚   â”œâ”€â”€ prompts/        # Prompt templates
â”‚   â”œâ”€â”€ chains/         # RAG chain logic
â”‚   â”œâ”€â”€ agents/         # Agents + tools (SQL, search, calculator)
â”‚   â”œâ”€â”€ eval/           # Evaluation harness
â”‚   â”œâ”€â”€ app.py          # Streamlit/FastAPI entrypoint
â”‚   â””â”€â”€ config.py       # Global settings
â”œâ”€â”€ tests/              # Unit tests
â””â”€â”€ docs/               # Docs + diagrams + demo GIF

## ğŸ› ï¸ Installation

### Requirements

- Python 3.9+
- `pip install -r requirements.txt`
- (Optional) Docker + docker-compose

### Setup
# Clone repo
git clone https://github.com/your-username/open-rag-template.git
cd open-rag-template

# Install dependencies
pip install -r requirements.txt

# Set your OpenAI API key
export OPENAI_API_KEY="your-api-key-here"

# Run app
streamlit run src/app.py

## âš¡ Usage

### Ingest documents
```bash
python src/ingest/pdf_loader.py data/my_docs/
```

### Run chatbot
```bash
streamlit run src/app.py
```

### Agent mode (SQL + tools)

Enable in config.py:
```python
ENABLE_AGENT_MODE = True
```

## ğŸ§ª Evaluation

### Run test suite:
```bash
python src/eval/evaluator.py
```

### Metrics included:

- Embedding similarity (semantic closeness).
- LLM-as-judge scoring (quality, groundedness, helpfulness).
- Custom test cases via eval/test_cases.json.

## ğŸŒ± Roadmap

âœ… Phase 1: Core RAG chatbot

âœ… Phase 2: Hybrid retrieval & re-ranking

ğŸ”„ Phase 3: LangChain agent mode (SQL, web search, calculator)

ğŸ”„ Phase 4: Evaluation harness + dashboard

ğŸ”² Phase 5: Fine-tuning (LoRA, instruction datasets)

## ğŸ¤ Contributing

Contributions welcome! Open issues, suggest features, or submit PRs.

## ğŸ“œ License

MIT License â€” free to use, modify, and share.

## â­ Why Star This Repo?

If you find this useful, give it a â­ on GitHub! It helps others discover the project and keeps development going.

## ğŸ”¥ With this README, anyone can:

- Understand what the project does.
- Install + run it in minutes.
- See that it's modular and professional.
- Know there's a roadmap for growth.